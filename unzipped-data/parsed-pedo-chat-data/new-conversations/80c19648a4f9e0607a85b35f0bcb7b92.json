{
    "id": "80c19648a4f9e0607a85b35f0bcb7b92",
    "messages": [
        "f139aba52f9fa1394b4034a7954b2220 (16:10): with the ElementTree API in python, how do I check the node type of a node to make sure it's an Element and not a comment?",
        "f139aba52f9fa1394b4034a7954b2220 (16:12): the reason I need that is that I'm using html5lib's parseFragment to parse in a source file, and this returns an array of elements and comments.  I then need the script to ignore the comments and process the elements",
        "b25b6b77a0087ff8385941e5545d32ea (16:13): you could use isinstance(node, etree.Element)",
        "f139aba52f9fa1394b4034a7954b2220 (16:14): in what package is the isinstance method defined?",
        "a924fb58d2c25874322f4e5126f608b9 (16:15): figured ElementTree would only have Elements",
        "ab7faae5d7b250ea8606486575f8f79c (16:15): discovers (too late) that upgrading one's LaTeX installation while simultaneously writing a paper in LaTeX is probably a bad idea",
        "a924fb58d2c25874322f4e5126f608b9 (16:15): isinstance is a builtin",
        "fefe4c60d912e295e59fd874577ca7f9 (16:15): ab7faae5d7b250ea8606486575f8f79c: hell yes :)",
        "f139aba52f9fa1394b4034a7954b2220 (16:16): a924fb58d2c25874322f4e5126f608b9, it does, but it treats comments as a special type of element, and so it makes the etree.iselement() method useless is this case.",
        "f139aba52f9fa1394b4034a7954b2220 (16:16): if (isinstance(node, etree.Element)):",
        "f139aba52f9fa1394b4034a7954b2220 (16:16): TypeError: isinstance() arg 2 must be a class, type, or tuple of classes and types",
        "ab7faae5d7b250ea8606486575f8f79c (16:16): (particularly when this is Gentoo, and so it spends a long time compiling code and regenerating font files and everything)",
        "1f58faf0d058f303f30239a369808167 (16:17): f139aba52f9fa1394b4034a7954b2220: xml.etree.ElementTree.iselement(element)",
        "f139aba52f9fa1394b4034a7954b2220 (16:17): 1f58faf0d058f303f30239a369808167, see my comment above to a924fb58d2c25874322f4e5126f608b9",
        "1f58faf0d058f303f30239a369808167 (16:17): ah just read ;)",
        "a924fb58d2c25874322f4e5126f608b9 (16:17): f139aba52f9fa1394b4034a7954b2220: Well, do all comments have the same tagname? E.g. #comment",
        "b25b6b77a0087ff8385941e5545d32ea (16:18): f139aba52f9fa1394b4034a7954b2220: Ah I forgot Element is a constructor",
        "f139aba52f9fa1394b4034a7954b2220 (16:18): all the comments look like &lt;!-- The foo Element --&gt;",
        "b25b6b77a0087ff8385941e5545d32ea (16:18): You use node.tag == etree.Comment",
        "b25b6b77a0087ff8385941e5545d32ea (16:18): remembers doing this now",
        "b25b6b77a0087ff8385941e5545d32ea (16:18): I admit that is not quite obvious",
        "ab7faae5d7b250ea8606486575f8f79c (16:19): f139aba52f9fa1394b4034a7954b2220: Use re.replace('&lt;!--.*?--&gt;', '', markup) before passing it to the parser, and then you know they're not comments",
        "b25b6b77a0087ff8385941e5545d32ea (16:19): ab7faae5d7b250ea8606486575f8f79c: Just because you did something stupid with LaTeX doesn't mean that you shouldn't play nice with the other children",
        "f139aba52f9fa1394b4034a7954b2220 (16:20): b25b6b77a0087ff8385941e5545d32ea, that worked.",
        "f139aba52f9fa1394b4034a7954b2220 (16:20): (except I used != instead of ==)",
        "1f58faf0d058f303f30239a369808167 (16:20): ab7faae5d7b250ea8606486575f8f79c: huh?",
        "f139aba52f9fa1394b4034a7954b2220 (16:21): now I'm trying to use the element.find() method, but the documentation is really poor. http://effbot.org/zone/pythondoc-elementtree-ElementTree.htm#elementtree.ElementTree.ElementTree.find-method",
        "b25b6b77a0087ff8385941e5545d32ea (16:21): (you could also use not isinstance(node, etree._Comment) but that seems more like a hack",
        "b25b6b77a0087ff8385941e5545d32ea (16:21): f139aba52f9fa1394b4034a7954b2220: What do you want to do?",
        "b25b6b77a0087ff8385941e5545d32ea (16:21): in lxml you should just use .xpath instead for almost everything",
        "f139aba52f9fa1394b4034a7954b2220 (16:21): oops, I linked to the wrong one...",
        "f139aba52f9fa1394b4034a7954b2220 (16:22): http://effbot.org/zone/pythondoc-elementtree-ElementTree.htm#elementtree.ElementTree._ElementInterface.find-method",
        "b25b6b77a0087ff8385941e5545d32ea (16:22): (iirc .find is like .xpath but with less features)",
        "f139aba52f9fa1394b4034a7954b2220 (16:22): it doesn't define what syntax the path needs to use though",
        "b25b6b77a0087ff8385941e5545d32ea (16:23): f139aba52f9fa1394b4034a7954b2220: Originally it only searched children",
        "b25b6b77a0087ff8385941e5545d32ea (16:23): So it would just be .find(tagname)",
        "b25b6b77a0087ff8385941e5545d32ea (16:23): iirc",
        "b25b6b77a0087ff8385941e5545d32ea (16:23): Now I think you can do desendants too",
        "1f58faf0d058f303f30239a369808167 (16:23): b25b6b77a0087ff8385941e5545d32ea: did you look at lxml for writing html5lib http://codespeak.net/lxml/",
        "f139aba52f9fa1394b4034a7954b2220 (16:24): How do I do descendants, because node.find(&quot;code&quot;) doesn't work, because the &lt;code&gt; elements I'm looking for aren't children of the node",
        "1f58faf0d058f303f30239a369808167 (16:24): f139aba52f9fa1394b4034a7954b2220: the find use a classical path",
        "b25b6b77a0087ff8385941e5545d32ea (16:25): f139aba52f9fa1394b4034a7954b2220 http://effbot.org/zone/element-xpath.htm documents the syntax",
        "b25b6b77a0087ff8385941e5545d32ea (16:25): 1f58faf0d058f303f30239a369808167: I don't understand the question. html5lib can use lxml as the tree representation but it implements a parser",
        "1f58faf0d058f303f30239a369808167 (16:25): f139aba52f9fa1394b4034a7954b2220 do you want to find all descendants ?",
        "b25b6b77a0087ff8385941e5545d32ea (16:26): f139aba52f9fa1394b4034a7954b2220: By far the easiest thing to do is node.xpath(&quot;//code&quot;)",
        "b25b6b77a0087ff8385941e5545d32ea (16:26): .xpath accepts any xpath 1.0",
        "b25b6b77a0087ff8385941e5545d32ea (16:26): .find accepts some subset",
        "1f58faf0d058f303f30239a369808167 (16:26): for ph in content.findall(&quot;.//{http://www.w3.org/1999/xhtml}code&quot;):  in XHTML ;)",
        "1f58faf0d058f303f30239a369808167 (16:27): for ph in content.findall(&quot;.//code&quot;):  in HTML ;)",
        "b25b6b77a0087ff8385941e5545d32ea (16:27): mutters something about the XML tax",
        "1f58faf0d058f303f30239a369808167 (16:27): hehe",
        "1f58faf0d058f303f30239a369808167 (16:28): has no problem with it",
        "1f58faf0d058f303f30239a369808167 (16:28): in my code I declare it at the start, and then I do not have to worry about it",
        "ab7faae5d7b250ea8606486575f8f79c (16:28): We should cut the XML tax by 2.5% and allow people to use the shorter namespace http://www.w3.org/1999/html to stimulate the XML economy",
        "b25b6b77a0087ff8385941e5545d32ea (16:29): f139aba52f9fa1394b4034a7954b2220: In general, if you don't care about compat. with non-lxml etree implementations then you should jsut use .xpath for pretty much all cases like this. It is blazing fast and well documented to the extent that xpath is well documented",
        "b25b6b77a0087ff8385941e5545d32ea (16:30): 1f58faf0d058f303f30239a369808167: Unless you don't know whether the document was parsed as XHTML or HTML up front",
        "1f58faf0d058f303f30239a369808167 (16:31): b25b6b77a0087ff8385941e5545d32ea: what do you mean? you know it if you parse it",
        "f139aba52f9fa1394b4034a7954b2220 (16:32): b25b6b77a0087ff8385941e5545d32ea, does xpath return a single element or a list of elements?",
        "b25b6b77a0087ff8385941e5545d32ea (16:32): f139aba52f9fa1394b4034a7954b2220: a list",
        "f139aba52f9fa1394b4034a7954b2220 (16:32): good, that's what I need",
        "f139aba52f9fa1394b4034a7954b2220 (16:33): I need a list so I can deal with the way elements like h1 to h6 are defined together in the spec",
        "1f58faf0d058f303f30239a369808167 (16:33): I wonder if Fredrik is in the process of porting to Python 3.0",
        "f139aba52f9fa1394b4034a7954b2220 (16:33): fwiw, this is the source document I'm working from http://dev.w3.org/html5/html-author/utils/elements.html (which is itself, generated from the spec using another script)",
        "1f58faf0d058f303f30239a369808167 (16:33): because ElementTree 1.3 is in beta for a very long time",
        "f139aba52f9fa1394b4034a7954b2220 (16:34): anyway, the script I'm writing now is using the data in that to build the table of elements and their associated categories.",
        "1f58faf0d058f303f30239a369808167 (16:35): f139aba52f9fa1394b4034a7954b2220: do you detect specific class or id?",
        "b25b6b77a0087ff8385941e5545d32ea (16:36): 1f58faf0d058f303f30239a369808167: You could have a system that accepts both XML and HTML and parses them both to etrees. But the differences between the two formats mean that you always need to keep a record of which format you parsed in and use the correct tag names for each case",
        "b25b6b77a0087ff8385941e5545d32ea (16:36): Python 3.0rc1+ (py3k, Oct 28 2008, 09:23:29).",
        "b25b6b77a0087ff8385941e5545d32ea (16:36): &gt;&gt;&gt; from xml.etree import ElementTree",
        "b25b6b77a0087ff8385941e5545d32ea (16:36): &gt;&gt;&gt;",
        "1f58faf0d058f303f30239a369808167 (16:36): ah cool",
        "1f58faf0d058f303f30239a369808167 (16:37): installed ElementTree 1.3 alpha locally http://effbot.org/zone/elementtree-13-intro.htm",
        "b25b6b77a0087ff8385941e5545d32ea (16:38): 1f58faf0d058f303f30239a369808167: Does 1.3 have parent pointers?",
        "1f58faf0d058f303f30239a369808167 (16:39): hmm I don't know. I installed it, specifically for ET.register_namespace()",
        "1f58faf0d058f303f30239a369808167 (16:40): but at first sight it doesn't seem",
        "f139aba52f9fa1394b4034a7954b2220 (16:46): 1f58faf0d058f303f30239a369808167, what class or id are you referring to?",
        "1f58faf0d058f303f30239a369808167 (16:48): f139aba52f9fa1394b4034a7954b2220: I don't know. You said you were building a list, and I was wondering how you were scoping the right elements. In my code usually I subscope by id or class",
        "1f58faf0d058f303f30239a369808167 (16:49): example",
        "1f58faf0d058f303f30239a369808167 (16:49): for ph in billet.findall(&quot;.//{http://www.w3.org/1999/xhtml}meta&quot;):",
        "1f58faf0d058f303f30239a369808167 (16:49): if ph.attrib.has_key('name') and ph.attrib['name'] == 'keywords':",
        "1f58faf0d058f303f30239a369808167 (16:49): keywords = ph.attrib['content']",
        "1f58faf0d058f303f30239a369808167 (16:49): return keywords",
        "b25b6b77a0087ff8385941e5545d32ea (16:52): barely remembers that has_key exists",
        "b25b6b77a0087ff8385941e5545d32ea (16:52): 'in' ftw",
        "a11aabeeceeae6b8cb5d12ea06b56554 (16:53): stretches",
        "a11aabeeceeae6b8cb5d12ea06b56554 (16:55): Is there any way to avoid having to prefix everything with {http://www.w3.org/1999/xhtml}?",
        "b8810fee2f4a71f849f3f7409546d1d9 (16:55): a11aabeeceeae6b8cb5d12ea06b56554: but namespaces FTW!",
        "f139aba52f9fa1394b4034a7954b2220 (16:58): 1f58faf0d058f303f30239a369808167, no, I'm just relying on the fact that I know the structure of the markup",
        "f139aba52f9fa1394b4034a7954b2220 (17:00): wtf?! The result I'm getting is not making any sense at all",
        "b25b6b77a0087ff8385941e5545d32ea (17:00): a11aabeeceeae6b8cb5d12ea06b56554: Not sure. Maybe using the Namespace API somehow but I'm not sure",
        "f139aba52f9fa1394b4034a7954b2220 (17:00): node.xpath(&quot;//table//tr[1]//li&quot;) is returning li items that are not descendants of node!",
        "b25b6b77a0087ff8385941e5545d32ea (17:00): In case you didn't realise I'm not sure",
        "b25b6b77a0087ff8385941e5545d32ea (17:02): f139aba52f9fa1394b4034a7954b2220: try  node.xpath(&quot;.//table//tr[1]//li&quot;)",
        "f139aba52f9fa1394b4034a7954b2220 (17:02): ah, it works if I use a &quot;.&quot; to match the current node. But it still makes no sense why it's searching the other nodes too node.xpath(&quot;.//table//tr[1]//li&quot;)",
        "b25b6b77a0087ff8385941e5545d32ea (17:02): is guessing",
        "b25b6b77a0087ff8385941e5545d32ea (17:03): f139aba52f9fa1394b4034a7954b2220: AIUI xpath treats // at the start of the expression as mean &quot;search from the document root&quot;",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:03): f139aba52f9fa1394b4034a7954b2220: It makes perfect sense!",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:03): Yeah",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:03): my feeling that it's way too early doesn't bode well for tomorrow when i have to get up even earlier",
        "f139aba52f9fa1394b4034a7954b2220 (17:03): but I don't have a document node. I'm using html5lib's parseFragment which is returning a list of Element nodes",
        "b25b6b77a0087ff8385941e5545d32ea (17:04): f139aba52f9fa1394b4034a7954b2220: Guess again",
        "f139aba52f9fa1394b4034a7954b2220 (17:04): b25b6b77a0087ff8385941e5545d32ea, no.",
        "b25b6b77a0087ff8385941e5545d32ea (17:04): lxml has no concept of a node without a document",
        "f139aba52f9fa1394b4034a7954b2220 (17:04): ah, well, that's just confusing",
        "b25b6b77a0087ff8385941e5545d32ea (17:04): I guess s/lxml/libxml2/ probably",
        "f139aba52f9fa1394b4034a7954b2220 (17:04): I really wish lxml had selectors api support so I didn't have to work with this xpath nonsense",
        "78885357e970c69de0c33081760a04c9 (17:05): http://codespeak.net/lxml/dev/cssselect.html",
        "b25b6b77a0087ff8385941e5545d32ea (17:05): 78885357e970c69de0c33081760a04c9: I was going to say that",
        "b25b6b77a0087ff8385941e5545d32ea (17:05): meanie",
        "b25b6b77a0087ff8385941e5545d32ea (17:05): ;)",
        "78885357e970c69de0c33081760a04c9 (17:05): shuffles back to his cave",
        "b25b6b77a0087ff8385941e5545d32ea (17:06): f139aba52f9fa1394b4034a7954b2220: Bonus points if you get it to run the selectors api testsuite :)",
        "f139aba52f9fa1394b4034a7954b2220 (17:07): awesome",
        "ab7faae5d7b250ea8606486575f8f79c (17:08): f139aba52f9fa1394b4034a7954b2220: You should write you code in JS in a browser, rather than in Python",
        "f139aba52f9fa1394b4034a7954b2220 (17:12): ab7faae5d7b250ea8606486575f8f79c, if I had a JavaScript engine avaialble with DOM support that would let me run javascripts from the command line and write to standard output, then I would",
        "b25b6b77a0087ff8385941e5545d32ea (17:17): http://www.croczilla.com/jssh",
        "b25b6b77a0087ff8385941e5545d32ea (17:17): It sounds like more effort than just writing the python though",
        "f139aba52f9fa1394b4034a7954b2220 (17:21): nice. I will look at that later",
        "1f58faf0d058f303f30239a369808167 (17:27): a11aabeeceeae6b8cb5d12ea06b56554: you can create a variable for the namespace, so you can shorten the typing ;)",
        "78885357e970c69de0c33081760a04c9 (17:34): wonders when 69b0d3dfe919a6b860a9fac82de52a7e is planning on doing a check-in for the authoring stylesheet work...",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:35): when i reach the bottom :-)",
        "78885357e970c69de0c33081760a04c9 (17:35): (the multipage and w3c versions seem to be quite a bit out-of-sync with the whatwg single page... maybe it is no big deal.)",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:35): about 51% in so far, by line",
        "ab7faae5d7b250ea8606486575f8f79c (17:35): 78885357e970c69de0c33081760a04c9: I assume it's when he's reached 110%",
        "ab7faae5d7b250ea8606486575f8f79c (17:35): 69b0d3dfe919a6b860a9fac82de52a7e: I hope you're going to annotate the acknowledgements section so it only lists people who have contributed to the author-relevant sections of the spec",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:36): ab7faae5d7b250ea8606486575f8f79c: i do intend to annotate the acknowledgements section though not along those lines",
        "b25b6b77a0087ff8385941e5545d32ea (17:37): Just personal insults about the contrbuters?",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:37): nah",
        "69b0d3dfe919a6b860a9fac82de52a7e (17:37): just hiding one paragraph that makes no sense to the author section",
        "ab7faae5d7b250ea8606486575f8f79c (17:37): The $10,000 one?",
        "ab7faae5d7b250ea8606486575f8f79c (17:38): I'd prefer a version with insults",
        "ab7faae5d7b250ea8606486575f8f79c (17:38): as long as they're entertaining ones",
        "f139aba52f9fa1394b4034a7954b2220 (17:40): ab7faae5d7b250ea8606486575f8f79c, use the annotation system to insert notes into the spec :-)",
        "f139aba52f9fa1394b4034a7954b2220 (17:40): s/notes/insults/",
        "ab7faae5d7b250ea8606486575f8f79c (17:42): f139aba52f9fa1394b4034a7954b2220: I can't, because I've set my browser to block access to the status script",
        "f139aba52f9fa1394b4034a7954b2220 (17:42): is that because it's slow?",
        "f139aba52f9fa1394b4034a7954b2220 (17:43): it no longer freezes Opera",
        "ab7faae5d7b250ea8606486575f8f79c (17:43): No, it's because it was slow"
    ],
    "person_ids": [
        "f139aba52f9fa1394b4034a7954b2220",
        "b25b6b77a0087ff8385941e5545d32ea",
        "a924fb58d2c25874322f4e5126f608b9",
        "ab7faae5d7b250ea8606486575f8f79c",
        "fefe4c60d912e295e59fd874577ca7f9",
        "1f58faf0d058f303f30239a369808167",
        "a11aabeeceeae6b8cb5d12ea06b56554",
        "b8810fee2f4a71f849f3f7409546d1d9",
        "69b0d3dfe919a6b860a9fac82de52a7e",
        "78885357e970c69de0c33081760a04c9"
    ]
}