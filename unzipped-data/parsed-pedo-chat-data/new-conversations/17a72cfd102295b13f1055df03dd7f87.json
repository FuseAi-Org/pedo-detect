{
    "id": "17a72cfd102295b13f1055df03dd7f87",
    "messages": [
        "cc097e0d7183ae8436e7df709553c8c0 (16:49): hmm, http://www.boingboing.net/2010/04/22/evil-witch-from-snow.html results in a page with nothing but an ad in opera and firefox with html5.enable, and nothing but the ad twice without html5.enable",
        "cc097e0d7183ae8436e7df709553c8c0 (16:50): with html5.enable it never stops loading",
        "cc097e0d7183ae8436e7df709553c8c0 (16:50): chrome loads as was intended",
        "e2633ed61085592add6e058692dfff2f (16:54): loads fine in firefox trunk",
        "b8810fee2f4a71f849f3f7409546d1d9 (16:58): cc097e0d7183ae8436e7df709553c8c0: how up-to-date is your build?",
        "b8810fee2f4a71f849f3f7409546d1d9 (16:58): cc097e0d7183ae8436e7df709553c8c0: wfm regardless of the pref in a build I made this week with some local patches",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:00): cc097e0d7183ae8436e7df709553c8c0: also wfm regardless of whether I have &quot;Firefox&quot; or &quot;Minefield&quot; in the UA string",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:01): cc097e0d7183ae8436e7df709553c8c0: broken in Opera for me, too",
        "cc097e0d7183ae8436e7df709553c8c0 (17:01): b8810fee2f4a71f849f3f7409546d1d9: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; en-US; rv:1.9.3a5pre) Gecko/20100417 Minefield/3.7a5pre",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:02): cc097e0d7183ae8436e7df709553c8c0: wfm with that UA string, too",
        "a924fb58d2c25874322f4e5126f608b9 (17:03): View source doesn't work, DOM only has a single ifram element",
        "a924fb58d2c25874322f4e5126f608b9 (17:03): *iframe",
        "cc097e0d7183ae8436e7df709553c8c0 (17:03): b8810fee2f4a71f849f3f7409546d1d9: with Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; en-US; rv:1.9.3a5pre) Gecko/20100423 Minefield/3.7a5pre i get two ads with html5.enable also",
        "f139aba52f9fa1394b4034a7954b2220 (17:03): cc097e0d7183ae8436e7df709553c8c0, works in Opera 10.10 for me. Fails in 10.50.",
        "f139aba52f9fa1394b4034a7954b2220 (17:04): cc097e0d7183ae8436e7df709553c8c0, check it in core, see where it regressed. I hope it's not a carakan bug",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:06): f139aba52f9fa1394b4034a7954b2220: Just because you were Carakan QA? :P",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:06): It's empty in 10.10 for me, having got zero bytes from the server",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:08): WFM in an actual Mac build, too",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:10): this polyglot spec isn't starting well",
        "b25b6b77a0087ff8385941e5545d32ea (17:11): b8810fee2f4a71f849f3f7409546d1d9: In what way?",
        "b25b6b77a0087ff8385941e5545d32ea (17:11): isn't really following",
        "f139aba52f9fa1394b4034a7954b2220 (17:11): I don't get the point of the polyglot spec. It seems like it's just an authoring guide, and mine already covers much of that info",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:11): b25b6b77a0087ff8385941e5545d32ea: in the way that it seems to repeat at least one superstition and in the way that bug reports about it have themselves been buggy",
        "f139aba52f9fa1394b4034a7954b2220 (17:11): anyway, I hope to find some time to get back to working on the authoring guide soon. It's been kind of left stagnant for far too long",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:12): s/bug reports/feedback on teh list/",
        "b25b6b77a0087ff8385941e5545d32ea (17:13): Polyglotness is so hard that even experts get it wrong? Who knew?",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:13): also, I can find terminology errors in Leif's and f139aba52f9fa1394b4034a7954b2220's emails in that thread",
        "f139aba52f9fa1394b4034a7954b2220 (17:14): my e-mails in which thread?",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:14): f139aba52f9fa1394b4034a7954b2220: &quot;then you should include the BOM indicating UTF-16LE&quot;",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:15): UTF-16LE is BOMless",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:15): the BOM indicates little-endian UTF-16",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:15): A leading U+FEFF is a ZWNBSP",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:15): (in UTF-16LE, UTF-16BE, UTF-32LE, UTF-32BE, etc.)",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:15): right",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:16): (it only isn't in UTF-8 because the spec specifically allows it, but assigns no meaning to it)",
        "f139aba52f9fa1394b4034a7954b2220 (17:16): I was using that as shorthand for indicating little-endian or big-endian, as indiciated by the BOM",
        "b25b6b77a0087ff8385941e5545d32ea (17:16): On the other hand Sam had just claimed that serving HTML as UTF-16 was non-conformant",
        "b8810fee2f4a71f849f3f7409546d1d9 (17:16): f139aba52f9fa1394b4034a7954b2220: I know. I'm nitpicking",
        "b25b6b77a0087ff8385941e5545d32ea (17:16): And he's chair of the freaking working group",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:16): I didn't think he did that",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:17): I took it to mean that HTML processors aren't required to support UTF-16, unlike XML",
        "a924fb58d2c25874322f4e5126f608b9 (17:17): I wouldn't mind if UTF-16 was non-conforming :)",
        "b25b6b77a0087ff8385941e5545d32ea (17:17): &quot;UTF-16 is not valid for HTML5&quot;",
        "b25b6b77a0087ff8385941e5545d32ea (17:17): I don't really know how to interpret that other than &quot;not valid&quot;",
        "b25b6b77a0087ff8385941e5545d32ea (17:18): If he meant &quot;not required to be supported&quot; then he should have said so",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:18): Try not literally interpreting anything. It might help with communication.",
        "f139aba52f9fa1394b4034a7954b2220 (17:18): a924fb58d2c25874322f4e5126f608b9, there's nothing inherently wrong with UTF-16. But it's more useful if your document contains a significant proportion of characters that would be represented as 3 or 4 octets in UTF-8, compared with just 2 in UTF-16",
        "b25b6b77a0087ff8385941e5545d32ea (17:19): Although the fact that UTF-16 is not required is basically a cop-out by the spec",
        "b25b6b77a0087ff8385941e5545d32ea (17:19): f139aba52f9fa1394b4034a7954b2220: That's much less common than you would think",
        "ab7faae5d7b250ea8606486575f8f79c (17:19): a11aabeeceeae6b8cb5d12ea06b56554: Communication works better when you ignore what somebody actually said and pretend they said something totally different?",
        "a924fb58d2c25874322f4e5126f608b9 (17:19): f139aba52f9fa1394b4034a7954b2220: Is it really? Even after applying gzip compression and such? And how many documents are affected?",
        "a11aabeeceeae6b8cb5d12ea06b56554 (17:20): ab7faae5d7b250ea8606486575f8f79c: Totally.",
        "ab7faae5d7b250ea8606486575f8f79c (17:20): a11aabeeceeae6b8cb5d12ea06b56554: I'm glad you agree it's a bad idea",
        "cc097e0d7183ae8436e7df709553c8c0 (17:20): b25b6b77a0087ff8385941e5545d32ea: maybe sam meant that UTF-16 isn't valid in &lt;meta charset&gt;",
        "b25b6b77a0087ff8385941e5545d32ea (17:20): remembers some study that looked at Japanese wikipedia and concluded that UTF-8 vs UTF-16 didn't make much difference",
        "a924fb58d2c25874322f4e5126f608b9 (17:20): It comes with downsides too, such as not being ascii-compatible, having both BE and LE variants + BOM variants of each, and trouble with surrogates (if it's not actually UCS2 in disguise, that is)",
        "ab7faae5d7b250ea8606486575f8f79c (17:21): f139aba52f9fa1394b4034a7954b2220: HTML documents are largely markup and URLs, which is all ASCII, so you need an extremely high density of raw text to make up for it",
        "ab7faae5d7b250ea8606486575f8f79c (17:21): (Also they're a lot of whitespace indentation and word-spacing, which is also ASCII)",
        "b25b6b77a0087ff8385941e5545d32ea (17:22): cc097e0d7183ae8436e7df709553c8c0: Possibly. Who knows? It wasn't what he said though.",
        "f139aba52f9fa1394b4034a7954b2220 (17:23): b25b6b77a0087ff8385941e5545d32ea, I expect it would be more common with asian language documents that contain a large amount of text, with comparitively little markup.",
        "f139aba52f9fa1394b4034a7954b2220 (17:23): I know that may not be common overall",
        "b25b6b77a0087ff8385941e5545d32ea (17:24): f139aba52f9fa1394b4034a7954b2220: It might make sense for the Japanese equivalent of Moby Dick on project Gutenberg",
        "b25b6b77a0087ff8385941e5545d32ea (17:24): It is something of an edge case on the web though",
        "ab7faae5d7b250ea8606486575f8f79c (17:25): I thought Project Gutenberg was text/plain",
        "b25b6b77a0087ff8385941e5545d32ea (17:25): http://www.gutenberg.org/files/2701/2701-h/2701-h.htm",
        "b25b6b77a0087ff8385941e5545d32ea (17:25): Not necessarily",
        "a924fb58d2c25874322f4e5126f608b9 (17:26): Well, plain text would be even better fodder for compression, wouldn't it?",
        "ab7faae5d7b250ea8606486575f8f79c (17:27): Yes, but that's irrelevant to what is allowed in HTML",
        "f139aba52f9fa1394b4034a7954b2220 (17:29): has anyone seen any stats on how common UTF-16 usage is on the web?",
        "f139aba52f9fa1394b4034a7954b2220 (17:30): http://trends.builtwith.com/encoding/UTF-16-UCS-2",
        "f139aba52f9fa1394b4034a7954b2220 (17:31): not sure how representative that is of the web in general. I suspect it was biased by a significant number of western lanagues, which are predominately the latin alphabet.",
        "f139aba52f9fa1394b4034a7954b2220 (17:32): would probably be more interesting to limit the sample to langauges where using UTF-16 is potentially useful",
        "ab7faae5d7b250ea8606486575f8f79c (17:36): f139aba52f9fa1394b4034a7954b2220: http://philip.html5.org/data/charsets.html#charset-utf-16 are the only ones I saw in a sample that's largely Western but still has thousands of .jp/.cn/etc pages",
        "f139aba52f9fa1394b4034a7954b2220 (17:39): ok, so it's usage is negligable.",
        "b25b6b77a0087ff8385941e5545d32ea (17:41): Hmm. I just tried comparing the UTF-8 and UTF-16 encoded size of some japanese wikipedia articles and it seemed that utf-8 was smaller overall, but I suspect I did something wrong",
        "a924fb58d2c25874322f4e5126f608b9 (17:42): Wikipedia has massive amounts of hidden markup, to be fair",
        "b25b6b77a0087ff8385941e5545d32ea (17:42): Is that atypical?",
        "a924fb58d2c25874322f4e5126f608b9 (17:43): I would think so",
        "a924fb58d2c25874322f4e5126f608b9 (17:43): Huge amounts of links, all of which are percent-encoded. Quite large head with inline &lt;script&gt; and such.",
        "b25b6b77a0087ff8385941e5545d32ea (17:47): http://event.rakuten.co.jp/borderless/index.html seems similar",
        "f139aba52f9fa1394b4034a7954b2220 (17:47): I got the same result with the jp Main_Page equivalent, and some other random article",
        "f139aba52f9fa1394b4034a7954b2220 (17:47): I then gzipped the results, and the UTF-8 still ended up smaller",
        "b25b6b77a0087ff8385941e5545d32ea (17:47): (in that case utf8 seems close to euc-jp which is the encoding the site uses)",
        "f139aba52f9fa1394b4034a7954b2220 (17:48): oh, I assumed the file I got from wikipedia was UTF-8.",
        "a924fb58d2c25874322f4e5126f608b9 (17:49): Isn't it?",
        "a924fb58d2c25874322f4e5126f608b9 (17:49): That's what I get, at least",
        "f139aba52f9fa1394b4034a7954b2220 (17:49): indeed, it is UTF-8. I don't know where you found a page using euc-jp",
        "a924fb58d2c25874322f4e5126f608b9 (17:50): b25b6b77a0087ff8385941e5545d32ea's link is euc-jp",
        "f139aba52f9fa1394b4034a7954b2220 (17:50): ah, I see. b25b6b77a0087ff8385941e5545d32ea wasn't talking about wikipedia being euc-jp",
        "b8810fee2f4a71f849f3f7409546d1d9 (18:01): the claim that UTF-16 is more compact for Japanese Web pages is a myth",
        "b8810fee2f4a71f849f3f7409546d1d9 (18:02): real Web pages have markup, inline scripts, whitespace, inline style, etc.",
        "b8810fee2f4a71f849f3f7409546d1d9 (18:03): b25b6b77a0087ff8385941e5545d32ea: a couple of years ago, I measured wikipedia pages re-encoded in various ways",
        "b8810fee2f4a71f849f3f7409546d1d9 (18:03): summary: gzipped UTF-8 is so good that everything else is pointless",
        "b25b6b77a0087ff8385941e5545d32ea (18:05): b8810fee2f4a71f849f3f7409546d1d9: That would agree with my 5-minute &quot;study&quot;",
        "b25b6b77a0087ff8385941e5545d32ea (18:06): Did you compare with euc-js and similar?",
        "b25b6b77a0087ff8385941e5545d32ea (18:06): Did you write it up?",
        "b8810fee2f4a71f849f3f7409546d1d9 (18:14): b25b6b77a0087ff8385941e5545d32ea: http://lists.w3.org/Archives/Public/public-html-comments/2008Jan/0048.html and http://lists.w3.org/Archives/Public/public-html-comments/2008Jan/0076.html",
        "b25b6b77a0087ff8385941e5545d32ea (18:18): b8810fee2f4a71f849f3f7409546d1d9: I think it would be great to blog any numbers that you have left over from that study",
        "a924fb58d2c25874322f4e5126f608b9 (18:23): Perhaps if we talk about it enough, ab7faae5d7b250ea8606486575f8f79c will make a service that takes a URL and outputs how big the page would be with different encodings and transfer options",
        "ab7faae5d7b250ea8606486575f8f79c (18:24): Surely you can do that with a single line of shell code",
        "ab7faae5d7b250ea8606486575f8f79c (18:24): using curl and iconv and gzip and wc and some loops",
        "a924fb58d2c25874322f4e5126f608b9 (18:30): ab7faae5d7b250ea8606486575f8f79c: Pretend this line is reverse psychology tricking you into making it to prove it's really possible in one line",
        "ab7faae5d7b250ea8606486575f8f79c (18:39): wget http://www.gutenberg.org/files/31757/31757-h/31757-h.htm; perl -e'for$c(qw(utf-8 utf-16be utf-16le utf-32 euc-jp shift-jis)){for$g(&quot; &quot;,&quot;|gzip -c&quot;){print &quot;$c$g &quot;.`iconv -c 31757-h.htm -f utf-8 -t $c$g|wc -c`}}'",
        "a924fb58d2c25874322f4e5126f608b9 (18:41): Accepted",
        "ab7faae5d7b250ea8606486575f8f79c (18:43): Interestingly the results are far tighter (and better) if you use bzip2",
        "a924fb58d2c25874322f4e5126f608b9 (18:43): Is the default gzip compression level a reasonable assumption?",
        "ab7faae5d7b250ea8606486575f8f79c (18:46): Yes",
        "ab7faae5d7b250ea8606486575f8f79c (18:46): Don't know if it's a correct assumption, though",
        "ab7faae5d7b250ea8606486575f8f79c (18:46): Strangely, xz (LZMA) is slightly worse than bzip2 here",
        "a924fb58d2c25874322f4e5126f608b9 (18:50): Not much difference with maximum compression on gzip anyhow",
        "ab7faae5d7b250ea8606486575f8f79c (18:52): You can save ~7% over gzip -9 by using 7z's gzip implementation",
        "ab7faae5d7b250ea8606486575f8f79c (18:54): (...though you wouldn't do that dynamically on a web server because it's way too slow)",
        "ab7faae5d7b250ea8606486575f8f79c (18:55): (but it's good whenever you're precomputing compressed files)",
        "70bfd0ae2cfbf2da192bddd569cf6132 (19:03): Heyo!",
        "a924fb58d2c25874322f4e5126f608b9 (19:05): ab7faae5d7b250ea8606486575f8f79c: But it doesn't seem to change the relative ranking of the methods",
        "a924fb58d2c25874322f4e5126f608b9 (19:05): That's the most important thing, I think",
        "ab7faae5d7b250ea8606486575f8f79c (19:14): a924fb58d2c25874322f4e5126f608b9: The most important thing is the size of the output, since the author's goal is to minimise that",
        "ab7faae5d7b250ea8606486575f8f79c (19:14): and if using a better compression implementation gives you a larger percentage gain than changing the charset, it's probably better for people to focus on the former before worrying too much about the latter",
        "a924fb58d2c25874322f4e5126f608b9 (19:16): Compression is a different trade-off, though, since it also requires resources to (de)compress",
        "ab7faae5d7b250ea8606486575f8f79c (19:16): I guess so",
        "ab7faae5d7b250ea8606486575f8f79c (19:16): It's more complex to changing the compression code and to make it cached so it goes fast etc",
        "ab7faae5d7b250ea8606486575f8f79c (19:17): so maybe it's better to do dumb stuff like recompress static files on every single request, and make easy changes like reencoding the static file",
        "a924fb58d2c25874322f4e5126f608b9 (19:18): But of course, in the end it's the size in actual bytes that matters",
        "ab7faae5d7b250ea8606486575f8f79c (19:19): Most compression algorithms seem to be designed to maximise resource usage on compression and minimise on decompression",
        "ab7faae5d7b250ea8606486575f8f79c (19:20): (e.g. LZMA can happily use 1GB RAM to compress, and a tenth of that for decompression)",
        "ab7faae5d7b250ea8606486575f8f79c (19:21): which seems precisely the wrong way around when you're doing compression on a single centralised server, and decompression on a thousand fast unutilised desktop PCs simultaneously",
        "88d4d34a8064a4ff39fd5e144eea7762 (19:33): ab7faae5d7b250ea8606486575f8f79c, the server can cache the compressed files.",
        "88d4d34a8064a4ff39fd5e144eea7762 (19:33): Assuming they're more or less static."
    ],
    "person_ids": [
        "cc097e0d7183ae8436e7df709553c8c0",
        "e2633ed61085592add6e058692dfff2f",
        "b8810fee2f4a71f849f3f7409546d1d9",
        "a924fb58d2c25874322f4e5126f608b9",
        "f139aba52f9fa1394b4034a7954b2220",
        "a11aabeeceeae6b8cb5d12ea06b56554",
        "b25b6b77a0087ff8385941e5545d32ea",
        "ab7faae5d7b250ea8606486575f8f79c",
        "70bfd0ae2cfbf2da192bddd569cf6132",
        "88d4d34a8064a4ff39fd5e144eea7762"
    ]
}