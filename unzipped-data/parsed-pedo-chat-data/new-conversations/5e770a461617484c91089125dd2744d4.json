{
    "id": "5e770a461617484c91089125dd2744d4",
    "messages": [
        "0a83bef6398eb4e5d40ea8f07aed823a (13:07): I'm looking for broken html pages with lot of markup errors to test a parser, does anyone know where can I find it? (does the html validator at w3.org keep an high-score list of the sites with most errors?)",
        "8b3687499080633e1898fa1dd209ef81 (13:08): Maybe try google.com?",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:08): 0a83bef6398eb4e5d40ea8f07aed823a: Alexa keeps a list like that",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:08): I found http://www.trentmueller.com/Top-10-Websites-with-the-Worst-HTML_Article/",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:09): but those sites now have less errors",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:09): a9b326df4e6da61c5b6f5e1058be83a2, a list of sites with broken html?",
        "b25b6b77a0087ff8385941e5545d32ea (13:09): 0a83bef6398eb4e5d40ea8f07aed823a: http://code.google.com/p/html5lib/source/browse/#hg%2Ftestdata%2Ftree-construction",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:10): http://www.alexa.com/topsites",
        "b25b6b77a0087ff8385941e5545d32ea (13:10): heh",
        "cc097e0d7183ae8436e7df709553c8c0 (13:12): a9b326df4e6da61c5b6f5e1058be83a2: do the stars indicate the brokenness?",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:12): haha",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:12): I already tested the parser with 1000 popular sites, but I was looking for websites like http://www.dokimos.org/ajff/",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:12): number of errors per page is not a great metric",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:12): it's the quality of the errors that matter",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:13): any jackass can ring up the error meter just by putting a bunch of &amp;s or such",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:13): 0a83bef6398eb4e5d40ea8f07aed823a: oh man",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:13): how'd you find that one?",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:14): this is gold",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:14): googling for &quot;worst websites&quot; or something similar",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:14): the security warning at the top is genius",
        "8b3687499080633e1898fa1dd209ef81 (13:14): Forget all the other browsers and",
        "8b3687499080633e1898fa1dd209ef81 (13:14): down with the Web 2.0 net police.",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:14): but it only has 375 errors on the main page",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:15): Error: meta element between head and body.",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:15): (the people who signed the guestbook seem to like it though)",
        "a9b326df4e6da61c5b6f5e1058be83a2 (13:15): that's the kind of thoughtful error I'm talking about",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:16): I assume that a website made with word and photoshop and put together with frontpage has enough creative errors",
        "b25b6b77a0087ff8385941e5545d32ea (13:18): 0a83bef6398eb4e5d40ea8f07aed823a: Seriously, have you tried the tests I linked to",
        "b25b6b77a0087ff8385941e5545d32ea (13:18): ?",
        "b25b6b77a0087ff8385941e5545d32ea (13:18): If you pass those you shoud do fine on websites",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:19): I'm looking at them, but I was searching for real-world pages (it's also easy for me to wget them and use them in my tests)",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:19): thanks for the link btw!",
        "b25b6b77a0087ff8385941e5545d32ea (13:19): Passing the tests is much more likely to be helpful than finding real world pages",
        "b25b6b77a0087ff8385941e5545d32ea (13:19): They are much easier to debug too :)",
        "b25b6b77a0087ff8385941e5545d32ea (13:20): The only thing that they really lack is crazy-deep nesting and so on",
        "cc097e0d7183ae8436e7df709553c8c0 (13:21): 0a83bef6398eb4e5d40ea8f07aed823a: what do you use the parser for?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:21): it's the Python built-in parser",
        "cc097e0d7183ae8436e7df709553c8c0 (13:21): ah",
        "cc097e0d7183ae8436e7df709553c8c0 (13:22): well i can only concur with b25b6b77a0087ff8385941e5545d32ea, you really want to pass the testsuite",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:22): my goal right now is to make it able to parse everything without errors, the next goal is to make it parse everything as correctly as possible (following the html5 standard)",
        "b25b6b77a0087ff8385941e5545d32ea (13:22): I don't understand the difference between those goals",
        "cc097e0d7183ae8436e7df709553c8c0 (13:23): just implement the parsing algorithm in the spec, it covers all cases",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:23): right now when the parser finds invalid markup it just raises an error and give up parsing, and there's nothing you can do",
        "b25b6b77a0087ff8385941e5545d32ea (13:23): Unless you consider &quot;without error&quot; to simply mean &quot;not throwing&quot;. In which case lambda html:&quot;&quot; meets the goal",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:24): and I'm changing that so that it tries to figure out what to do with the invalid markup and keep going till the end",
        "8b3687499080633e1898fa1dd209ef81 (13:24): You're modifying an existing parser?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:24): cc097e0d7183ae8436e7df709553c8c0, I can't start from scratch, so I'm adapting what I have to get closer to the specs gradually",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:24): yes",
        "8b3687499080633e1898fa1dd209ef81 (13:24): I... wouldn't recommend that",
        "cc097e0d7183ae8436e7df709553c8c0 (13:25): why can't you start from scratch?",
        "8b3687499080633e1898fa1dd209ef81 (13:25): I don't know of anybody who's done that",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:25): well, so far I managed to have it parse a list of 1000 pages successfully with 0 errors, so it's going quite well",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:26): cc097e0d7183ae8436e7df709553c8c0, because I could just use html5lib if I wanted a python parser that follows the specs",
        "b25b6b77a0087ff8385941e5545d32ea (13:26): Pretty sure we had this conversation before",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:26): we did",
        "b25b6b77a0087ff8385941e5545d32ea (13:27): But if I were you I would wrap html5lib in an API that looks more like the stdlib",
        "b25b6b77a0087ff8385941e5545d32ea (13:27): Rather than trying to make the internals of the stdlib more like html5lib",
        "cc097e0d7183ae8436e7df709553c8c0 (13:27): so you want something that is closer to the spec, but still isn't 100% compliant?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:28): but the goal is providing a better html parser in the stdlib, and improving the existing one is the only viable solution (replacing it with html5lib is not really an option)",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:28): cc097e0d7183ae8436e7df709553c8c0, I want to get as close as 100% compliant as possible",
        "cc097e0d7183ae8436e7df709553c8c0 (13:29): why is replacing it with html5lib not an option?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:29): but if it does the wrong thing with some obscure corner cases it probably doesn't matter too much now",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:31): cc097e0d7183ae8436e7df709553c8c0, for several reason, if html5lib is added to the stdlib it will have to follow the python release schedule (so you have to wait many months between releases), it needs someone willing to maintain it, it needs to have a compatible license, it has to be &quot;good enough&quot; to get in the stdlib and replace the existing one and have everyone to switch and so on",
        "b25b6b77a0087ff8385941e5545d32ea (13:32): So it would get a faster release schedule than today?",
        "b25b6b77a0087ff8385941e5545d32ea (13:32): has neglected html5lib recently",
        "b25b6b77a0087ff8385941e5545d32ea (13:33): The license shouldn't be a problem",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:33): how often do you make html5lib releases?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:33): for python is more or less 16 months for new features and maybe 4 for bug fixes",
        "b25b6b77a0087ff8385941e5545d32ea (13:33): Well, uh, the last one was a few years ago. It is horribly out of date compared to trunk. This is somewhat embarassing",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:34): are people even using it?",
        "b25b6b77a0087ff8385941e5545d32ea (13:34): It turns out that at any given moment there is always something more fun to do than make a release",
        "b25b6b77a0087ff8385941e5545d32ea (13:34): Yeah, we get a steady flow of bug reports",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): and Mozilla use it in their html sanitizer, for example",
        "8b3687499080633e1898fa1dd209ef81 (13:35): 345bbbd3b0a531dc6b5cb762d8823711, so about your canvas tests...",
        "8b3687499080633e1898fa1dd209ef81 (13:35): b25b6b77a0087ff8385941e5545d32ea, oh?",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): (most of the bug reports as Invalid, I should say)",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): 8b3687499080633e1898fa1dd209ef81: The one you use on your websites",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:35): do they use the development version then?",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): Nothing in the browser ofc",
        "8b3687499080633e1898fa1dd209ef81 (13:35): Oh",
        "8b3687499080633e1898fa1dd209ef81 (13:35): Those people use git",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): And for that they are to be praised",
        "b25b6b77a0087ff8385941e5545d32ea (13:35): :p",
        "b25b6b77a0087ff8385941e5545d32ea (13:36): 0a83bef6398eb4e5d40ea8f07aed823a: I am not sure. A release is long, long overdue. And if I could do one right away I think I would now feel guilty enough to do one",
        "b25b6b77a0087ff8385941e5545d32ea (13:37): But we will see how the feeling persists to this evening",
        "8b3687499080633e1898fa1dd209ef81 (13:37): b25b6b77a0087ff8385941e5545d32ea, today isn't do what the hell you want day?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:38): these are some numbers about Python html parser btw: http://dpaste.com/699552/",
        "b25b6b77a0087ff8385941e5545d32ea (13:38): Nope :|",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:39): the percentage represent the pages parsed till the end with no errors",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:39): (with a sample of ~1000 pages)",
        "345bbbd3b0a531dc6b5cb762d8823711 (13:42): 0a83bef6398eb4e5d40ea8f07aed823a: Have you tried parsing e.g. a PDF file and seeing if that hits any errors?",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:42): nope",
        "345bbbd3b0a531dc6b5cb762d8823711 (13:43): vaguely remembers a few difficulties with such files when parsing lots of random pages, though maybe that was just because he hadn't implemented a length limit before then",
        "345bbbd3b0a531dc6b5cb762d8823711 (13:46): 0a83bef6398eb4e5d40ea8f07aed823a: If you want a larger selection of real-world pages to test, http://www.dotnetdotcom.org/ has something like half a million",
        "0a83bef6398eb4e5d40ea8f07aed823a (13:48): thanks"
    ],
    "person_ids": [
        "0a83bef6398eb4e5d40ea8f07aed823a",
        "8b3687499080633e1898fa1dd209ef81",
        "a9b326df4e6da61c5b6f5e1058be83a2",
        "b25b6b77a0087ff8385941e5545d32ea",
        "cc097e0d7183ae8436e7df709553c8c0",
        "345bbbd3b0a531dc6b5cb762d8823711"
    ]
}